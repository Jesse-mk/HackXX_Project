{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Notes\n",
    "#### From CSES Presentation at HackXX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.sents() # the sentences in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.word_tokenize(#string to turn into array of text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test:\n",
    "    - Capitalization\n",
    "    - list comprehension to turn tokens into strings (can make 1 large corpus and make them all lower if want using for loop and concat all (\n",
    "    - can use regex to substitute out else\n",
    "    - re.sub(r'[^a-zA-Z0-9 .]' , '', large_corpus), can conserve periods to break up into sentences.\n",
    "    - get rid of stopwords (and/or/etc.)\n",
    "    - stemming\n",
    "    - TF-IDF (how important a word is in a certain document) - how many times the word appears in a doc vs how unique a word is in this document itself.\n",
    "    - nltk.FreqDist(tokens).most_common(500) gives top 500 words.\n",
    "    - every sentence is diff lengths, have different sized vectors for diff docs. but want same vector length for ML.\n",
    "    - TFIDF of top 500 words. give it a TF-IDF non zero value. (not binary). taken every sentence into 500 vectorization of TFIDF vectors.\n",
    "    - none in top 500 words, all 0's.\n",
    "    -use for sentiment analysis. given new sentence, how happy/sad is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cont.\n",
    "    - -1, 0, 1 for scale.\n",
    "    - phrases are turned into vector. \n",
    "    - TFIDF on entire text but only apply to a small sample. (works better so still able to work).\n",
    "    - save IDF score for so many words\n",
    "    - look at class sizes. make sure resample so classes are equal.\n",
    "    - SVM (some work better than others)\n",
    "    - can predict using the classifier how pos/neg you are.\n",
    "    - no top 500 word, just assume it's most common (neutral class). 50/5 thousand = good so all terms are there.\n",
    "    - LSTM/deep learning for translation > corpus and embed every word is a value itself. Word embeddings and words have meaning themselves not just documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "1. what model is best? Is RF good for multiclass?\n",
    "2. SVM. make a hyperplane. this one has a kernel for different dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas: use stemming (salads and salad). same word, allows the machine learning model to detemine what the word means for models. can sometimes change the meaning of the word itself.\n",
    "\n",
    "from nltk.stem import WrodNetLemmatizer:\n",
    "\n",
    "look at word and determine what type of word it is. mapping the word and meaning. takes WAY longer than stemming but takes into account context.\n",
    "\n",
    "TFIDF: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot: \n",
    "widely used and simulates human interactions.\n",
    "companies are making chatboxes to automating services.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Websites: External APIs:\n",
    "\n",
    "wit.ai, IBM watson API, DialogFlow > fetch data from you, do NLP and return the appropriate data/langauge/etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wit.ai good for fb messenger since bought by fb.\n",
    "\n",
    "IBM watson API is huge AI powered service, not only NLP and every form of ML.\n",
    "\n",
    "DialogFlow:\n",
    "conversational experienced developed by google. fundamental concepts. connect UIs to bot and send data to and through to achieve goal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "createa bot that can organize a hackathon and problem is swag, so want to keep inventory and bot that manages inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firebase is really easy to get started wiht, use UI based interactions to create/read/write. Firebase Cloud Functions, connect dialogflow and database together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents: Help convert user requests into actionable data/response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fundamentals of dialogflow: \n",
    "- agents: help convert user requests into actionable data/response.\n",
    "- intents: configured by developers which indicate what the objective of the user might be when they make a specific request. \n",
    "- training phrases: collections of possible utterances that users migth say to match an intent. \n",
    "- entities help extract info from user speech with the help of prompts. ex: how many small sized tshirts left?\n",
    "- response: a textual based response given back to the user.\n",
    "- fulfillment: code that fulfills a user request.\n",
    "- intents: events: trigger intent from nonverbal signals like clicking or etc.\n",
    "- entity: can give meaning to words (ie yahoo and google and etc labeled as \"companies\").\n",
    "- storage of name inside chatbot is stored.\n",
    "- responses: none if no chat\n",
    "- fulfillment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- size and elements are main parameters.\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can createa db in firebase. \n",
    "- inside inventory can add bottles and companies associated with the bottles\n",
    "- tshirts have something similar. \n",
    "- user query, filter out important pieces and then return.\n",
    "- filter out what a user is using and then use terms to figure out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- count gives you # tshirts associated with size. \n",
    "- snapshot.child"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
